nudge_y = 0.02) +
geom_smooth(method=lm, se=TRUE) +
xlab("Time (s), log2 scale") +
ylab("Mean precision") +
ggtitle("BirdNET precision by species total singing/calling time \n(only species with ≥10 detections)")
dev.off()
xenocanto_foreground_recordings_by_species <- read.csv("../CSVs/xenocanto_foreground_recordings_for_selected_species.csv")
species_labels <- rbind(species_labels,
c("Ath noc", "Athene noctua"),
c("Cor nix", "Corvus cornix"),
c("Cur ibe", "Curruca iberiae"),
c("Cur ala", "Curruca melanocephala"),
c("Dry mar", "Dryocopus martius"),
c("Gal the", "Galerida theklae"),
c("Ixo min", "Ixobrychus minutus"),
c("Lan col", "Lanius collurio"),
c("Lan sen", "Lanius senator"),
c("Mus str", "Muscicapa striata"),
c("Pho pho", "Phoenicurus phoenicurus"),
c("Phy ibe", "Phylloscopus ibericus"),
c("Tri neb", "Tringa nebularia"))
precision_results_by_available_recordings_for_selected_species <- precision_results_by_species %>%
filter(total_detections >= 10) %>%
left_join(xenocanto_foreground_recordings_by_species,
by = "species") %>%
left_join(species_labels %>%
select(species, label),
by = "species")
jpeg(file = paste0("../R plots/BirdNET_", BirdNET_version, ds_text, filtered_text, overlap_text, "/BirdNET precision analysis/precision_by_xenocanto_foreground_recordings_(only_species_with_at_least_10_detections).jpeg"), width = 3300, height = 2400, res = 500)
ggplot(precision_results_by_available_recordings_for_selected_species, aes(x=log2(n_xenocanto_foreground_recordings), y=mean_precision, label=label)) +
geom_point() +
geom_text_repel(size = 2.5,
nudge_y = 0.02) +
geom_smooth(method=lm, se=TRUE) +
xlab("Number of recordings, log2 scale") +
ylab("Mean precision") +
ggtitle("BirdNET precision by species number of foreground recordings on Xeno-canto (only species with ≥10 detections)")
dev.off()
# Checking the normality of the precision distribution to determine whether we can perform a Pearson correlation analysis or not
shapiro.test(precision_results_by_available_recordings_for_selected_species$mean_precision)
hist(precision_results_by_available_recordings_for_selected_species$mean_precision)
shapiro.test(log2(precision_results_by_available_recordings_for_selected_species$n_xenocanto_foreground_recordings))
hist(log2(precision_results_by_available_recordings_for_selected_species$n_xenocanto_foreground_recordings))
# The distribution of the logarithm of the total number of foreground recordings available on Xeno-canto is normal, but the distribution of precision values is not.
# Therefore, we have to transform it before we can perform the Pearson's correlation analysis.
# Nonetheless, neither sqrt nor logarithmic nor 1/x transformations transform the precision distribution into a normal.
# Thus, a Spearman's correlation test will have to be performed insted of a Pearson's one.
cor.test(log2(precision_results_by_available_recordings_for_selected_species$n_xenocanto_foreground_recordings), precision_results_by_available_recordings_for_selected_species$mean_precision, method = "spearman")
# Spearman's correlation coefficient is 0.485, with a p-value of 0.00015, which indicates that total number of foreground recordings on Xeno-canto significantly influences precision results.
selected_recall_and_precision_results_by_species <- recall_and_precision_results_by_species %>%
filter(total_detections >= 10)
# Checking the normality of the precision distribution to determine whether we can perform a Pearson correlation analysis or not
shapiro.test(selected_recall_and_precision_results_by_species$mean_precision)
hist(selected_recall_and_precision_results_by_species$mean_precision)
shapiro.test(selected_recall_and_precision_results_by_species$total_time)
hist(selected_recall_and_precision_results_by_species$total_time)
# The distribution of total_time is normal, but the distribution of precision values is not.
# Therefore, we have to transform it before we can perform the Pearson's correlation analysis.
# Nonetheless, neither sqrt nor logarithmic nor 1/x transformations transform the precision distribution into a normal.
# Thus, a Spearman's correlation test will have to be performed insted of a Pearson's one.
cor.test(selected_recall_and_precision_results_by_species$total_time, selected_recall_and_precision_results_by_species$mean_precision, method = "spearman")
# Spearman's correlation coefficient is 0.778, with a p-value of 4.24e-07, which indicates that total singing time significantly improves precision results.
# Plotting BirdNET precision by species
jpeg(file = paste0("../R plots/BirdNET_", BirdNET_version, ds_text, filtered_text, overlap_text, "/BirdNET precision analysis/precision_by_species_with_at_least_10_detections.jpeg"), width = 7500, height = 2400, res = 500)
ggplot(precision_results_by_species %>%
filter(total_detections >= 10), aes(x=reorder(reorder(species_number, -total_detections), mean_precision), y=mean_precision)) +
geom_bar(position=position_dodge(),
stat="identity",
colour='black',
fill = "#759ED0") +
xlab("Species") +
ylab("Mean precision") +
ggtitle("Mean precision by bird species in BirdNET identifications — only species with ≥10 detections") +
theme_bw() +
theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))
dev.off()
}
#--------------------------Recall analysis-----------------------------------
recall_results_by_species <- recall_results_by_species %>%
left_join(recall_and_precision_results_by_species %>%
select(species, original_time),
by = "species") %>%
mutate(minutes = round(round(original_time, 0)/60, 0),
seconds = round(round(original_time, 0) %% 60, 0),
species_number = paste0(species, " (n = ", total_manual_detections, ")"),
species_time = paste0(species, " (t = ", case_when(minutes > 0 ~ paste0(minutes, "m "),
TRUE ~ ""), round(seconds, 0), "s)"))
# Plotting BirdNET recall by species
jpeg(file = paste0("../R plots/BirdNET_", BirdNET_version, ds_text, filtered_text, overlap_text, "/BirdNET recall analysis/recall_(proportion_of_time_detected)_by_species_", confidence_labels[i], ".jpeg"), width = 5000, height = 2400, res = 500)
ggplot(recall_results_by_species, aes(x=reorder(reorder(species_time, -total_manual_detections), mean_proportion_of_time_detected), y=mean_proportion_of_time_detected)) +
geom_bar(position=position_dodge(),
stat="identity",
colour='black',
fill = "#759ED0") +
ylim(0, 1) +
xlab("Species") +
ylab("Proportion of vocalization time\ncorrectly detected") +
ggtitle(paste0("Proportion of vocalization time correctly detected by BirdNET by bird species", confidence_plot_titles[i])) +
theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))
dev.off()
jpeg(file = paste0("../R plots/BirdNET_", BirdNET_version, ds_text, filtered_text, overlap_text, "/BirdNET recall analysis/recall_(proportion_of_recordings_where_detected)_by_species_", confidence_labels[i], ".jpeg"), width = 7500, height = 2400, res = 500)
ggplot(recall_results_by_species, aes(x=reorder(reorder(species_number, -total_manual_detections), mean_recall), y=mean_recall)) +
geom_bar(position=position_dodge(),
stat="identity",
colour='black',
fill = "#759ED0") +
xlab("Species") +
ylab("Mean recall") +
ggtitle(paste0("Mean BirdNET recall by bird species — only identifications", confidence_plot_titles[i])) +
theme_bw()  +
theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))
dev.off()
# Only species having sung or called at least 30 seconds
if (i == 1) {
# Plotting BirdNET recall by total singing/calling time
jpeg(file = paste0("../R plots/BirdNET_", BirdNET_version, ds_text, filtered_text, overlap_text, "/BirdNET recall analysis/recall_by_total_time.jpeg"), width = 3300, height = 2400, res = 500)
ggplot(recall_and_precision_results_by_species, aes(x=total_time, y=mean_recall, label=label)) +
geom_point() +
geom_text_repel(size = 2.5,
nudge_y = 0.02) +
xlab("Time (s), log2 scale") +
ylab("Mean recall") +
ggtitle("BirdNET recall by species total singing/calling time")
dev.off()
recall_results_with_total_time_as_factor <- recall_and_precision_results_by_species %>%
mutate(time_factor = case_when(original_time < 10 ~ "0-10",
original_time >= 10 & original_time < 60 ~ "10-60",
original_time >= 60 & original_time < 500 ~ "60-500",
TRUE ~ "≥500"))
recall_results_with_total_time_as_factor$time_factor <- factor(recall_results_with_total_time_as_factor$time_factor,
levels=c("0-10", "10-60", "60-500", "≥500"))
jpeg(file = paste0("../R plots/BirdNET_", BirdNET_version, ds_text, filtered_text, overlap_text, "/BirdNET recall analysis/recall_by_total_time_boxplot.jpeg"), width = 3300, height = 2400, res = 500)
ggplot(recall_results_with_total_time_as_factor, aes(x=time_factor, y=mean_recall)) +
geom_boxplot() +
xlab("Time (s)") +
ylab("Mean recall") +
ggtitle("BirdNET recall by species total singing/calling time")
dev.off()
recall_results_with_time_per_recording_as_factor <- recall_and_precision_results_by_species %>%
left_join(total_birds_detected %>%
select(species, n_recordings_clearly_detected),
by = "species") %>%
mutate(time_per_recording = original_time / n_recordings_clearly_detected,
time_per_recording_factor = case_when(time_per_recording < 5 ~ "<5",
time_per_recording >= 5 & time_per_recording < 10 ~ "5-10",
time_per_recording >= 10 & time_per_recording < 20 ~ "10-20",
TRUE ~ "≥20"))
recall_results_with_time_per_recording_as_factor$time_per_recording_factor <- factor(recall_results_with_time_per_recording_as_factor$time_per_recording_factor,
levels=c("<5", "5-10", "10-20", "≥20"))
jpeg(file = paste0("../R plots/BirdNET_", BirdNET_version, ds_text, filtered_text, overlap_text, "/BirdNET recall analysis/recall_by_time_per_recording_boxplot.jpeg"), width = 3300, height = 2400, res = 500)
ggplot(recall_results_with_time_per_recording_as_factor, aes(x=time_per_recording_factor, y=mean_recall)) +
geom_boxplot() +
xlab("Time (s)") +
ylab("Mean recall") +
ggtitle("BirdNET recall by species average singing/calling time per recording")
dev.off()
jpeg(file = paste0("../R plots/BirdNET_", BirdNET_version, ds_text, filtered_text, overlap_text, "/BirdNET recall analysis/recall_(proportion_of_time_detected)_by_species_with_at_least_30s.jpeg"), width = 4000, height = 2400, res = 500)
ggplot(recall_results_by_species_with_at_least_30s, aes(x=reorder(reorder(species_number, -total_manual_detections), mean_proportion_of_time_detected), y=mean_proportion_of_time_detected)) +
geom_bar(position=position_dodge(),
stat="identity",
colour='black',
fill = "#759ED0") +
ylim(0, 1) +
xlab("Species") +
ylab("Proportion of vocalization time correctly detected") +
ggtitle("Proportion of vocalization time correctly detected by BirdNET by bird species with ≥30 seconds of total time") +
theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))
dev.off()
jpeg(file = paste0("../R plots/BirdNET_", BirdNET_version, ds_text, filtered_text, overlap_text, "/BirdNET recall analysis/recall_(proportion_of_recordings_where_detected)_by_species_with_at_least_30s.jpeg"), width = 7500, height = 2400, res = 500)
ggplot(recall_results_by_species_with_at_least_30s, aes(x=reorder(reorder(species_number, -total_manual_detections), mean_recall), y=mean_recall)) +
geom_bar(position=position_dodge(),
stat="identity",
colour='black',
fill = "#759ED0") +
xlab("Species") +
ylab("Mean recall") +
ggtitle(paste0("Mean BirdNET recall by bird species with ≥30 seconds of total vocalization time — only identifications", confidence_plot_titles[1])) +
theme_bw() +
theme(axis.text.x = element_markdown(angle = 90, hjust = 1, vjust = 0.5))
dev.off()
recall_results_by_available_recordings_for_selected_species <- recall_results_by_species_with_at_least_30s %>%
left_join(xenocanto_foreground_recordings_by_species,
by = "species")
jpeg(file = paste0("../R plots/BirdNET_", BirdNET_version, ds_text, filtered_text, overlap_text, "/BirdNET recall analysis/recall_by_xenocanto_foreground_recordings_(only_species_with_at_least_30_seconds).jpeg"), width = 3300, height = 2400, res = 500)
ggplot(recall_results_by_available_recordings_for_selected_species, aes(x=log2(n_xenocanto_foreground_recordings), y=mean_recall, label=label)) +
geom_point() +
geom_text_repel(size = 2.5,
nudge_y = 0.02) +
geom_smooth(method=lm, se=TRUE) +
xlab("Number of recordings, log2 scale") +
ylab("Mean recall") +
ggtitle("BirdNET recall by species number of foreground recordings on Xeno-canto (only species with ≥30 seconds of total vocalization time)")
dev.off()
# Checking the normality of the recall distribution to determine whether we can perform a Pearson correlation analysis or not
shapiro.test(recall_results_by_available_recordings_for_selected_species$mean_recall)
hist(recall_results_by_available_recordings_for_selected_species$mean_recall)
shapiro.test(log2(recall_results_by_available_recordings_for_selected_species$n_xenocanto_foreground_recordings))
hist(log2(recall_results_by_available_recordings_for_selected_species$n_xenocanto_foreground_recordings))
# Both distributions are normal. Therefore, we can perform Pearson's correlation analysis.
cor.test(log2(recall_results_by_available_recordings_for_selected_species$n_xenocanto_foreground_recordings), recall_results_by_available_recordings_for_selected_species$mean_recall, method = "pearson")
# Pearson's correlation coefficient is -0.328, with a p-value of 0.051, which indicates that total number of foreground recordings on Xeno-canto does not significantly reduces recall results.
}
}
#--------------Global detection results by confidence threshold-----------------
annotations <- read.csv("../CSVs/annotations.csv")
recordings <- read.csv("../CSVs/recordings_extended.csv")
for (i in 1:length(confidence_levels)) {
temp_global_detection_results <- BirdNET_precision_results %>%
filter(confidence >= confidence_levels[i]) %>%
group_by(recording_id, species) %>%
summarize(correct_identifications = sum(as.numeric(correct_identification)),
incorrect_identifications = sum(as.numeric(!correct_identification))) %>%
mutate(correct_identifications = case_when(correct_identifications > 0 ~ 1,
TRUE ~ 0),
incorrect_identifications = case_when(incorrect_identifications > 0 ~ 1,
TRUE ~ 0)) %>%
group_by(species) %>%
summarize(recordings_where_correctly_identified = sum(correct_identifications),
recordings_where_incorrectly_identified = sum(incorrect_identifications))
temp_detection_results_by_habitat <- BirdNET_precision_results %>%
left_join(recordings %>%
select(recording_id, habitat),
by = "recording_id") %>%
filter(confidence >= confidence_levels[i]) %>%
group_by(habitat, species) %>%
summarize(correct_identifications = sum(as.numeric(correct_identification)),
incorrect_identifications = sum(as.numeric(!correct_identification))) %>%
mutate(correct_identifications = case_when(correct_identifications > 0 ~ 1,
TRUE ~ 0),
incorrect_identifications = case_when(incorrect_identifications > 0 ~ 1,
TRUE ~ 0)) %>%
group_by(habitat) %>%
summarize(correctly_identified_species = sum(correct_identifications),
incorrectly_identified_species = sum(incorrect_identifications))
if (i == 1) {
global_BirdNET_detection_results_1st_threshold <- temp_global_detection_results
BirdNET_detection_results_by_habitat_1st_threshold <- temp_detection_results_by_habitat
} else if (i == 2) {
global_BirdNET_detection_results_2nd_threshold <- temp_global_detection_results
BirdNET_detection_results_by_habitat_2nd_threshold <- temp_detection_results_by_habitat
} else {
global_BirdNET_detection_results_3rd_threshold <- temp_global_detection_results
BirdNET_detection_results_by_habitat_3rd_threshold <- temp_detection_results_by_habitat
}
}
global_detection_results <- total_birds_detected %>%
filter(species != "Unidentified bird") %>%
select(species, n_recordings_clearly_detected) %>%
full_join(global_BirdNET_detection_results_1st_threshold,
by = "species") %>%
rename("correctly_identified_1st_threshold" = "recordings_where_correctly_identified",
"incorrectly_identified_1st_threshold" = "recordings_where_incorrectly_identified") %>%
full_join(global_BirdNET_detection_results_2nd_threshold,
by = "species") %>%
rename("correctly_identified_2nd_threshold" = "recordings_where_correctly_identified",
"incorrectly_identified_2nd_threshold" = "recordings_where_incorrectly_identified") %>%
full_join(global_BirdNET_detection_results_3rd_threshold,
by = "species") %>%
rename("correctly_identified_3rd_threshold" = "recordings_where_correctly_identified",
"incorrectly_identified_3rd_threshold" = "recordings_where_incorrectly_identified") %>%
arrange(species)
global_detection_results[is.na(global_detection_results)] <- 0
global_detection_results <- global_detection_results %>%
mutate(non_present_species_1st_threshold = as.numeric(n_recordings_clearly_detected == 0 & incorrectly_identified_1st_threshold > 0) * incorrectly_identified_1st_threshold,
non_present_species_2nd_threshold = as.numeric(n_recordings_clearly_detected == 0 & incorrectly_identified_2nd_threshold > 0) * incorrectly_identified_2nd_threshold,
non_present_species_3rd_threshold = as.numeric(n_recordings_clearly_detected == 0 & incorrectly_identified_3rd_threshold > 0) * incorrectly_identified_3rd_threshold)
global_detection_results <- rbind(global_detection_results, c("Total detections",
sum(global_detection_results$n_recordings_clearly_detected),
sum(global_detection_results$correctly_identified_1st_threshold),
sum(global_detection_results$incorrectly_identified_1st_threshold),
sum(global_detection_results$correctly_identified_2nd_threshold),
sum(global_detection_results$incorrectly_identified_2nd_threshold),
sum(global_detection_results$correctly_identified_3rd_threshold),
sum(global_detection_results$incorrectly_identified_3rd_threshold),
sum(global_detection_results$non_present_species_1st_threshold),
sum(global_detection_results$non_present_species_2nd_threshold),
sum(global_detection_results$non_present_species_3rd_threshold)))
global_detection_results <- rbind(global_detection_results, c("Total species",
sum(as.numeric(global_detection_results$n_recordings_clearly_detected > 0)) - 1,
sum(as.numeric(global_detection_results$correctly_identified_1st_threshold > 0)) - 1,
sum(as.numeric(global_detection_results$incorrectly_identified_1st_threshold > 0)) - 1,
sum(as.numeric(global_detection_results$correctly_identified_2nd_threshold > 0)) - 1,
sum(as.numeric(global_detection_results$incorrectly_identified_2nd_threshold > 0)) - 1,
sum(as.numeric(global_detection_results$correctly_identified_3rd_threshold > 0)) - 1,
sum(as.numeric(global_detection_results$incorrectly_identified_3rd_threshold > 0)) - 1,
sum(as.numeric(global_detection_results$non_present_species_1st_threshold > 0)) - 1,
sum(as.numeric(global_detection_results$non_present_species_2nd_threshold > 0)) - 1,
sum(as.numeric(global_detection_results$non_present_species_3rd_threshold > 0)) - 1))
global_detection_results_file_name <- file.path(paste0("../CSVs/BirdNET_", BirdNET_version, ds_text, filtered_text, overlap_text), "global_detection_results.csv")
write.csv(x=global_detection_results, file=global_detection_results_file_name, row.names = FALSE)
#-------------Global detection results by time of day and habitat---------------
bird_species_richness_by_recording_and_time <- annotations %>%
left_join(recordings, by = "recording_id") %>%
filter(confidence_level == 1, sound_type == "Bird") %>%
select(recording_id, recording_date, recording_time, label) %>%
unique() %>%
group_by(recording_id, recording_date, recording_time) %>%
summarize(n_bird_species = n())
bird_species_richness_by_time <- bird_species_richness_by_recording_and_time %>%
group_by(recording_time) %>%
summarize(mean_richness = mean(n_bird_species))
jpeg(file = "../R plots/Annotation analysis/number_of_species_detected_by_time_of_the_day.jpeg", width = 3000, height = 2400, res = 500)
ggplot(bird_species_richness_by_recording_and_time, aes(x = as.factor(recording_time), y = n_bird_species, fill = as.factor(recording_time))) +
geom_boxplot() +
xlab("Time of the day") +
ylab("Bird species detected") +
ggtitle("Bird species detected per minute by time of the day") +
theme_bw() +
theme(legend.position = "none") +
scale_fill_manual(values = c("#84B8E1", "#84B8E1", "#84B8E1"))
dev.off()
# Checking the normality of the distribution of the number of species detected per recording to determine whether we can perform an ANOVA analysis or not
shapiro.test(bird_species_richness_by_recording_and_time$n_bird_species)
hist(bird_species_richness_by_recording_and_time$n_bird_species)
# The distribution of the number of species per recording is not normal. Therefore, we have to transform the data before we can perform the ANOVA analysis.
# Nonetheless, neither sqrt nor logarithmic transformations transform the distribution into a normal one.
# Thus, a Kruskal-Wallis test will have to be performed insted of an ANOVA.
kruskal.test(n_bird_species ~ recording_time, data = bird_species_richness_by_recording_and_time)
# Performing t-tests to check whether the differences between the number of species detected at 7am and at 1pm are statistically significant.
t.test((bird_species_richness_by_recording_and_time %>%
filter(recording_time == "07:00:00"))$n_bird_species,
(bird_species_richness_by_recording_and_time %>%
filter(recording_time == "13:00:00"))$n_bird_species)
# Same test, this time comparing the number of species detected at 7am and at 0am.
t.test((bird_species_richness_by_recording_and_time %>%
filter(recording_time == "07:00:00"))$n_bird_species,
(bird_species_richness_by_recording_and_time %>%
filter(recording_time == "00:00:00"))$n_bird_species)
bird_species_richness_by_recording_and_habitat <- annotations %>%
left_join(recordings, by = "recording_id") %>%
filter(confidence_level == 1, sound_type == "Bird") %>%
select(station_id, habitat, label) %>%
unique() %>%
group_by(station_id, habitat) %>%
summarize(n_bird_species = n())
jpeg(file = "../R plots/Annotation analysis/number_of_species_detected_by_habitat.jpeg", width = 3000, height = 2400, res = 500)
ggplot(bird_species_richness_by_recording_and_habitat, aes(x = as.factor(habitat), y = n_bird_species, fill = as.factor(habitat))) +
geom_boxplot() +
xlab("Habitat") +
ylab("Bird species detected") +
ggtitle("Bird species detected per day by habitat") +
theme_bw() +
theme(legend.position = "none") +
scale_fill_manual(values = c("#84B8E1", "#84B8E1", "#84B8E1", "#84B8E1"))
dev.off()
# Checking the normality of the distribution of the number of species detected per recording to determine whether we can perform an ANOVA analysis or not
shapiro.test(bird_species_richness_by_recording_and_habitat$n_bird_species)
hist(bird_species_richness_by_recording_and_habitat$n_bird_species)
# The distribution of the number of species per recording can't be proven not to be normal. Therefore, we don't have to transform the data before we can perform the ANOVA analysis.
anova_species_richness_by_habitat <- aov(n_bird_species ~ as.factor(habitat), data = bird_species_richness_by_recording_and_habitat)
summary(anova_species_richness_by_habitat)
n_recordings_by_habitat <- recordings %>%
count(habitat) %>%
rename("Recordings analyzed" = "n")
bird_species_richness_by_habitat <- annotations %>%
left_join(recordings, by = "recording_id") %>%
filter(confidence_level == 1, sound_type == "Bird") %>%
select(recording_id, recording_date, habitat, label) %>%
unique() %>%
group_by(habitat, label) %>%
summarize(n_detections = n()) %>%
count(habitat) %>%
rename("Species annotated" = "n")
detection_results_by_habitat <- n_recordings_by_habitat %>%
left_join(bird_species_richness_by_habitat,
by = "habitat") %>%
left_join(BirdNET_detection_results_by_habitat_1st_threshold,
by = "habitat") %>%
rename("Correctly_identified_1st_threshold" = "correctly_identified_species",
"Incorrectly_identified_1st_threshold" = "incorrectly_identified_species") %>%
left_join(BirdNET_detection_results_by_habitat_2nd_threshold,
by = "habitat") %>%
rename("Correctly_identified_2nd_threshold" = "correctly_identified_species",
"Incorrectly_identified_2nd_threshold" = "incorrectly_identified_species") %>%
left_join(BirdNET_detection_results_by_habitat_3rd_threshold,
by = "habitat") %>%
rename("Correctly_identified_3rd_threshold" = "correctly_identified_species",
"Incorrectly_identified_3rd_threshold" = "incorrectly_identified_species",
"Habitat" = "habitat")
detection_results_by_habitat_file_name <- file.path(paste0("../CSVs/BirdNET_", BirdNET_version, ds_text, filtered_text), "detection_results_by_habitat.csv")
write.csv(x=detection_results_by_habitat, file=detection_results_by_habitat_file_name, row.names = FALSE)
# It calculates the Precision-Recall AUC for each habitat
BirdNET_PR_results_by_recording <- read.csv(paste0("../CSVs/BirdNET_", BirdNET_version, ds_text, filtered_text, overlap_text, "/BirdNET_PR_results_by_recording.csv"))
recording_info_extended <- read.csv("../CSVs/recordings_extended.csv")
BirdNET_PR_results_by_recording[is.na(BirdNET_PR_results_by_recording)] = 0
BirdNET_PR_results_by_recording_and_habitat <- BirdNET_PR_results_by_recording %>%
mutate(confidence_threshold = as.numeric(confidence_threshold)) %>%
left_join(recording_info_extended %>%
select(recording_id, habitat),
by = "recording_id") %>%
left_join(recording_acoustic_data %>%
select(recording_id, NDSI_left),
by = "recording_id")
pr_auc_by_recording <- data.frame()
for (i in 1:nrow(recordings)) {
BirdNET_PR_results_by_selected_recording <- BirdNET_PR_results_by_recording_and_habitat %>%
filter(recording_id == recordings[i,]$recording_id)
pr_auc <- abs(trapz(BirdNET_PR_results_by_selected_recording$precision, BirdNET_PR_results_by_selected_recording$recall))
pr_auc_by_recording <- rbind(pr_auc_by_recording, c(recordings[i,]$recording_id, pr_auc))
}
colnames(pr_auc_by_recording) <- c("recording_id", "AUC")
BirdNET_PR_results_by_recording_and_habitat <- BirdNET_PR_results_by_recording_and_habitat %>%
left_join(pr_auc_by_recording,
by = "recording_id") %>%
mutate(habitat = as.factor(habitat)) %>%
select(recording_id, habitat, NDSI_left, recall, precision) %>%
group_by(recording_id, habitat, NDSI_left) %>%
summarize(recall = mean(recall),
precision = mean(precision)) %>%
ungroup()
# Checking the normality of the distribution of the recall and precision variables to determine whether we can perform an ANOVA analysis or not
shapiro.test(BirdNET_PR_results_by_recording_and_habitat$recall)
hist(BirdNET_PR_results_by_recording_and_habitat$recall)
shapiro.test(BirdNET_PR_results_by_recording_and_habitat$precision)
hist(BirdNET_PR_results_by_recording_and_habitat$precision)
# The distribution of recall and precision values is not normal. Therefore, we have to transform them before we can perform the ANOVA analysis.
# Nonetheless, neither sqrt nor logarithmic transformations transform the recall and precision distributions into normal ones.
# Thus, a Kruskal-Wallis test will have to be performed insted of an ANOVA.
kruskal.test(recall ~ habitat, data = BirdNET_PR_results_by_recording_and_habitat)
kruskal.test(precision ~ habitat, data = BirdNET_PR_results_by_recording_and_habitat)
# Habitat does not seem to have a significant impact on neither recall nor precision.
BirdNET_recall_results_by_recording <- melt(setDT(BirdNET_PR_results_by_recording_and_habitat %>%
select(recording_id, recall)), id.vars = "recording_id", variable.name = "metric", value.name = "value")
BirdNET_precision_results_by_recording <- melt(setDT(BirdNET_PR_results_by_recording_and_habitat %>%
select(recording_id, precision)), id.vars = "recording_id", variable.name = "metric", value.name = "value")
BirdNET_recall_and_precision_results_by_habitat <- union_all(BirdNET_recall_results_by_recording, BirdNET_precision_results_by_recording) %>%
left_join(BirdNET_PR_results_by_recording_and_habitat %>%
select(recording_id, habitat),
by = "recording_id")
jpeg(file = paste0("../R plots/BirdNET_", BirdNET_version, ds_text, filtered_text, overlap_text, "/BirdNET precision and recall analysis/precision_and_recall_by_habitat.jpeg"), width = 3000, height = 2400, res = 500)
ggplot(BirdNET_recall_and_precision_results_by_habitat, aes(x = habitat, y = value, fill = metric)) +
geom_boxplot() +
xlab("Habitat") +
ylab("Value") +
labs(fill = "Metric") +
ggtitle("Precision and recall distributions by dominant habitat") +
theme_bw() +
scale_fill_manual(values = c("#E4959C", "#95B5DA"))
dev.off()
# Checking the normality of the NDSI index distribution to determine whether we can perform a Pearson correlation analysis or not
shapiro.test(BirdNET_PR_results_by_recording_and_habitat$NDSI_left)
hist(BirdNET_PR_results_by_recording_and_habitat$NDSI_left)
# The distribution of NDSI, recall and precision values is not normal.
# Therefore, we have to transform them before we can perform the Pearson's correlation analysis.
# Nonetheless, neither sqrt nor logarithmic transformations transform the NDSI, recall or precision distributions into normal ones.
# Thus, a Spearman's correlation test will have to be performed insted of a Pearson's one.
# The NDSI index has a significant influence on the precision of the algorithm (r = 0.218, p-value = 0.003)
cor.test(BirdNET_PR_results_by_recording_and_habitat$NDSI_left, BirdNET_PR_results_by_recording_and_habitat$precision, method = "spearman")
# The NDSI index has a significant influence on the recall of the algorithm (r = 0.178, p-value = 0.002)
cor.test(BirdNET_PR_results_by_recording_and_habitat$NDSI_left, BirdNET_PR_results_by_recording_and_habitat$recall, method = "spearman")
jpeg(file = paste0("../R plots/BirdNET_", BirdNET_version, ds_text, filtered_text, overlap_text, "/BirdNET precision analysis/precision_by_anthropic_noise.jpeg"), width = 3200, height = 2500, res = 500)
ggplot(BirdNET_PR_results_by_recording_and_habitat, aes(x=NDSI_left, y=precision)) +
geom_point(color = "black") +
geom_smooth(method = lm, se = FALSE) +
xlab("NDSI score") +
ylab("Precision") +
ggtitle("BirdNET precision by NDSI score") +
theme(panel.background = element_blank(),
axis.line = element_line())
dev.off()
jpeg(file = paste0("../R plots/BirdNET_", BirdNET_version, ds_text, filtered_text, overlap_text, "/BirdNET recall analysis/recall_by_anthropic_noise.jpeg"), width = 3200, height = 2500, res = 500)
ggplot(BirdNET_PR_results_by_recording_and_habitat, aes(x=NDSI_left, y=recall)) +
geom_point(color = "black") +
geom_smooth(method = lm, se = FALSE) +
xlab("NDSI score") +
ylab("Recall") +
ggtitle("BirdNET recall by NDSI score") +
theme(panel.background = element_blank(),
axis.line = element_line())
dev.off()
# ------------------------Recall by sample size analysis------------------------
global_detection_results <- read.csv(paste0("../CSVs/BirdNET_", BirdNET_version, ds_text, filtered_text, overlap_text, "/global_detection_results_by_recording_subset.csv"))
grouped_global_detection_results <- global_detection_results %>%
group_by(n_recordings_sampled, minimum_confidence_threshold) %>%
summarize(mean_n_species_correctly_detected = mean(n_species_correctly_detected),
mean_n_species_incorrectly_detected = mean(n_species_incorrectly_detected),
mean_total_species_detected = mean(total_species_detected)) %>%
mutate(proportion_of_species_correctly_detected = mean_n_species_correctly_detected/mean_total_species_detected,
proportion_of_species_incorrectly_detected = mean_n_species_incorrectly_detected/mean_total_species_detected)
jpeg(file = paste0("../R plots/BirdNET_", BirdNET_version, ds_text, filtered_text, overlap_text, "/BirdNET recall analysis/proportion_of_species_correctly_detected_by_n_recordings_sampled.jpeg"), width = 4000, height = 2500, res = 500)
ggplot(grouped_global_detection_results, aes(x = as.numeric(n_recordings_sampled), y = proportion_of_species_correctly_detected, fill = as.factor(minimum_confidence_threshold))) +
geom_bar(position = position_nudge(x = 0.5), stat = "identity",
colour = 'black') +
xlab("Number of recordings sampled") +
ylab("Proportion of species correctly detected") +
labs(fill = "Minimum confidence\nthreshold used") +
scale_fill_manual(values = c("#2b4056", "#3874a5", "#56b1f7")) +
ggtitle("Proportion of species correctly detected by number of recordings sampled") +
theme_bw()
dev.off()
jpeg(file = paste0("../R plots/BirdNET_", BirdNET_version, ds_text, filtered_text, overlap_text, "/BirdNET recall analysis/proportion_of_species_incorrectly_detected_by_n_recordings_sampled.jpeg"), width = 4000, height = 2500, res = 500)
ggplot(grouped_global_detection_results, aes(x = as.numeric(n_recordings_sampled), y = proportion_of_species_incorrectly_detected, fill = as.factor(minimum_confidence_threshold))) +
geom_bar(position = position_nudge(x = 0.5), stat = "identity",
colour = 'black') +
xlab("Number of recordings sampled") +
ylab("Proportion of species mistakenly detected") +
labs(fill = "Minimum confidence\nthreshold used") +
scale_fill_manual(values = c("#2b4056", "#3874a5", "#56b1f7")) +
ggtitle("Proportion of species mistakenly detected by number of recordings sampled") +
theme_bw()
dev.off()
global_detection_results <- global_detection_results %>%
mutate(proportion_of_species_correctly_detected = n_species_correctly_detected/total_species_detected,
proportion_of_species_incorrectly_detected = n_species_incorrectly_detected/total_species_detected)
correctly_detected_lm <- lm(proportion_of_species_correctly_detected ~ log(n_recordings_sampled) + as.numeric(minimum_confidence_threshold), data = global_detection_results)
summary(correctly_detected_lm)
# It appears that there is a linear correlation between the proportion of species correctly detected and the logarithm of the number of recordings sampled
# after controlling for the minimum confidence threshold used (p < 2e-16)
incorrectly_detected_lm <- lm(proportion_of_species_incorrectly_detected ~ log(n_recordings_sampled) + as.numeric(minimum_confidence_threshold), data = global_detection_results)
summary(incorrectly_detected_lm)
# The same does seem to be true as well of the proportion of species incorrectly detected (p < 2e-16)
source("~/Escriptori/Màster Ecologia/TFM/R scripts/compile_PR_results.R", echo=TRUE)
