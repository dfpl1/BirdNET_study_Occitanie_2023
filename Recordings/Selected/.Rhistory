global_BirdNET_detection_results_1st_threshold <- temp_global_detection_results
BirdNET_detection_results_by_habitat_1st_threshold <- temp_detection_results_by_habitat
} else if (i == 2) {
global_BirdNET_detection_results_2nd_threshold <- temp_global_detection_results
BirdNET_detection_results_by_habitat_2nd_threshold <- temp_detection_results_by_habitat
} else {
global_BirdNET_detection_results_3rd_threshold <- temp_global_detection_results
BirdNET_detection_results_by_habitat_3rd_threshold <- temp_detection_results_by_habitat
}
}
global_detection_results <- total_birds_detected %>%
filter(species != "Unidentified bird") %>%
select(species, n_recordings_clearly_detected) %>%
full_join(global_BirdNET_detection_results_1st_threshold,
by = "species") %>%
rename("correctly_identified_1st_threshold" = "recordings_where_correctly_identified",
"incorrectly_identified_1st_threshold" = "recordings_where_incorrectly_identified") %>%
full_join(global_BirdNET_detection_results_2nd_threshold,
by = "species") %>%
rename("correctly_identified_2nd_threshold" = "recordings_where_correctly_identified",
"incorrectly_identified_2nd_threshold" = "recordings_where_incorrectly_identified") %>%
full_join(global_BirdNET_detection_results_3rd_threshold,
by = "species") %>%
rename("correctly_identified_3rd_threshold" = "recordings_where_correctly_identified",
"incorrectly_identified_3rd_threshold" = "recordings_where_incorrectly_identified") %>%
arrange(species) %>%
ungroup()
global_detection_results[is.na(global_detection_results)] <- 0
global_detection_results <- global_detection_results %>%
mutate(non_present_species_1st_threshold = as.numeric(n_recordings_clearly_detected == 0 & incorrectly_identified_1st_threshold > 0) * incorrectly_identified_1st_threshold,
non_present_species_2nd_threshold = as.numeric(n_recordings_clearly_detected == 0 & incorrectly_identified_2nd_threshold > 0) * incorrectly_identified_2nd_threshold,
non_present_species_3rd_threshold = as.numeric(n_recordings_clearly_detected == 0 & incorrectly_identified_3rd_threshold > 0) * incorrectly_identified_3rd_threshold)
global_detection_results <- rbind(global_detection_results, c("Total detections",
sum(global_detection_results$n_recordings_clearly_detected),
sum(global_detection_results$correctly_identified_1st_threshold),
sum(global_detection_results$incorrectly_identified_1st_threshold),
sum(global_detection_results$correctly_identified_2nd_threshold),
sum(global_detection_results$incorrectly_identified_2nd_threshold),
sum(global_detection_results$correctly_identified_3rd_threshold),
sum(global_detection_results$incorrectly_identified_3rd_threshold),
sum(global_detection_results$non_present_species_1st_threshold),
sum(global_detection_results$non_present_species_2nd_threshold),
sum(global_detection_results$non_present_species_3rd_threshold)))
global_detection_results <- rbind(global_detection_results, c("Total species",
sum(as.numeric(global_detection_results$n_recordings_clearly_detected > 0)) - 1,
sum(as.numeric(global_detection_results$correctly_identified_1st_threshold > 0)) - 1,
sum(as.numeric(global_detection_results$incorrectly_identified_1st_threshold > 0)) - 1,
sum(as.numeric(global_detection_results$correctly_identified_2nd_threshold > 0)) - 1,
sum(as.numeric(global_detection_results$incorrectly_identified_2nd_threshold > 0)) - 1,
sum(as.numeric(global_detection_results$correctly_identified_3rd_threshold > 0)) - 1,
sum(as.numeric(global_detection_results$incorrectly_identified_3rd_threshold > 0)) - 1,
sum(as.numeric(global_detection_results$non_present_species_1st_threshold > 0)) - 1,
sum(as.numeric(global_detection_results$non_present_species_2nd_threshold > 0)) - 1,
sum(as.numeric(global_detection_results$non_present_species_3rd_threshold > 0)) - 1))
global_detection_results_file_name <- file.path(paste0(CSV_path), "global_detection_results.csv")
write.csv(x=global_detection_results, file=global_detection_results_file_name, row.names = FALSE)
#-------------Global detection results by time of day and habitat---------------
bird_species_richness_by_recording_and_time <- annotations %>%
left_join(recordings, by = "recording_id") %>%
filter(confidence_level == 1, sound_category == "Bird") %>%
select(recording_id, recording_date, recording_time, label) %>%
unique() %>%
group_by(recording_id, recording_date, recording_time) %>%
summarize(n_bird_species = n())
bird_species_richness_by_time <- bird_species_richness_by_recording_and_time %>%
group_by(recording_time) %>%
summarize(mean_richness = mean(n_bird_species))
jpeg(file = "../R plots/Annotation analysis/number_of_species_detected_by_time_of_the_day.jpeg", width = 3000, height = 2400, res = 500)
ggplot(bird_species_richness_by_recording_and_time, aes(x = as.factor(recording_time), y = n_bird_species, fill = as.factor(recording_time))) +
geom_boxplot() +
xlab("Time of the day") +
ylab("Bird species detected") +
ggtitle("Bird species detected per minute by time of the day") +
theme_bw() +
theme(legend.position = "none") +
scale_fill_manual(values = c("#84B8E1", "#84B8E1", "#84B8E1"))
dev.off()
# Checking the normality of the distribution of the number of species detected per recording to determine whether we can perform an ANOVA analysis or not
shapiro.test(bird_species_richness_by_recording_and_time$n_bird_species)
hist(bird_species_richness_by_recording_and_time$n_bird_species)
# The distribution of the number of species per recording is not normal. Therefore, we have to transform the data before we can perform the ANOVA analysis.
# Nonetheless, neither sqrt nor logarithmic transformations transform the distribution into a normal one.
# Thus, a Kruskal-Wallis test will have to be performed insted of an ANOVA.
kruskal.test(n_bird_species ~ recording_time, data = bird_species_richness_by_recording_and_time)
# Performing t-tests to check whether the differences between the number of species detected at 7am and at 1pm are statistically significant.
t.test((bird_species_richness_by_recording_and_time %>%
filter(recording_time == "07:00:00"))$n_bird_species,
(bird_species_richness_by_recording_and_time %>%
filter(recording_time == "13:00:00"))$n_bird_species)
# Same test, this time comparing the number of species detected at 7am and at 0am.
t.test((bird_species_richness_by_recording_and_time %>%
filter(recording_time == "07:00:00"))$n_bird_species,
(bird_species_richness_by_recording_and_time %>%
filter(recording_time == "00:00:00"))$n_bird_species)
bird_species_richness_by_recording_and_habitat <- annotations %>%
left_join(recordings, by = "recording_id") %>%
filter(confidence_level == 1, sound_category == "Bird") %>%
select(station_id, habitat, label) %>%
unique() %>%
group_by(station_id, habitat) %>%
summarize(n_bird_species = n())
jpeg(file = "../R plots/Annotation analysis/number_of_species_detected_by_habitat.jpeg", width = 3000, height = 2400, res = 500)
ggplot(bird_species_richness_by_recording_and_habitat, aes(x = as.factor(habitat), y = n_bird_species, fill = as.factor(habitat))) +
geom_boxplot() +
xlab("Habitat") +
ylab("Bird species detected") +
ggtitle("Bird species detected per day by habitat") +
theme_bw() +
theme(legend.position = "none") +
scale_fill_manual(values = c("#84B8E1", "#84B8E1", "#84B8E1", "#84B8E1", "#84B8E1"))
dev.off()
# Checking the normality of the distribution of the number of species detected per recording to determine whether we can perform an ANOVA analysis or not
shapiro.test(bird_species_richness_by_recording_and_habitat$n_bird_species)
hist(bird_species_richness_by_recording_and_habitat$n_bird_species)
# The distribution of the number of species per recording can't be proven not to be normal. Therefore, we don't have to transform the data before we can perform the ANOVA analysis.
anova_species_richness_by_habitat <- aov(n_bird_species ~ as.factor(habitat), data = bird_species_richness_by_recording_and_habitat)
summary(anova_species_richness_by_habitat)
n_recordings_by_habitat <- recordings %>%
count(habitat) %>%
rename("Recordings analyzed" = "n")
bird_species_richness_by_habitat <- annotations %>%
left_join(recordings, by = "recording_id") %>%
filter(confidence_level == 1, sound_category == "Bird") %>%
select(recording_id, recording_date, habitat, label) %>%
unique() %>%
group_by(habitat, label) %>%
summarize(n_detections = n()) %>%
count(habitat) %>%
rename("Species annotated" = "n")
detection_results_by_habitat <- n_recordings_by_habitat %>%
left_join(bird_species_richness_by_habitat,
by = "habitat") %>%
left_join(BirdNET_detection_results_by_habitat_1st_threshold,
by = "habitat") %>%
rename("Correctly_identified_1st_threshold" = "correctly_identified_species",
"Incorrectly_identified_1st_threshold" = "incorrectly_identified_species") %>%
left_join(BirdNET_detection_results_by_habitat_2nd_threshold,
by = "habitat") %>%
rename("Correctly_identified_2nd_threshold" = "correctly_identified_species",
"Incorrectly_identified_2nd_threshold" = "incorrectly_identified_species") %>%
left_join(BirdNET_detection_results_by_habitat_3rd_threshold,
by = "habitat") %>%
rename("Correctly_identified_3rd_threshold" = "correctly_identified_species",
"Incorrectly_identified_3rd_threshold" = "incorrectly_identified_species",
"Habitat" = "habitat")
detection_results_by_habitat_file_name <- file.path(paste0("../CSVs", algorithm_text, BirdNET_version, ds_text, filtered_text), "detection_results_by_habitat.csv")
write.csv(x=detection_results_by_habitat, file=detection_results_by_habitat_file_name, row.names = FALSE)
# It calculates the Precision-Recall AUC for each habitat
BirdNET_PR_results_by_recording <- read.csv(paste0(CSV_path, "/", algorithm, "_PR_results_by_recording.csv"))
recording_info_extended <- read.csv("../CSVs/recordings_extended.csv")
BirdNET_PR_results_by_recording[is.na(BirdNET_PR_results_by_recording)] = 0
BirdNET_PR_results_by_recording_and_habitat <- BirdNET_PR_results_by_recording %>%
mutate(confidence_threshold = as.numeric(confidence_threshold)) %>%
left_join(recording_info_extended %>%
select(recording_id, habitat),
by = "recording_id") %>%
left_join(recording_acoustic_data %>%
select(recording_id, NDSI_left),
by = "recording_id")
pr_auc_by_recording <- data.frame()
for (i in 1:nrow(recordings)) {
BirdNET_PR_results_by_selected_recording <- BirdNET_PR_results_by_recording_and_habitat %>%
filter(recording_id == recordings[i,]$recording_id)
pr_auc <- abs(trapz(BirdNET_PR_results_by_selected_recording$precision, BirdNET_PR_results_by_selected_recording$recall))
pr_auc_by_recording <- rbind(pr_auc_by_recording, c(recordings[i,]$recording_id, pr_auc))
}
colnames(pr_auc_by_recording) <- c("recording_id", "AUC")
BirdNET_PR_results_by_recording_and_habitat <- BirdNET_PR_results_by_recording_and_habitat %>%
left_join(pr_auc_by_recording,
by = "recording_id") %>%
mutate(habitat = as.factor(habitat)) %>%
select(recording_id, habitat, NDSI_left, recall, precision, confidence_threshold) %>%
rename("rec_recall" = "recall",
"rec_precision" = "precision")
BirdNET_PR_results_by_recording_and_habitat_conf10 <- BirdNET_PR_results_by_recording_and_habitat %>%
filter(confidence_threshold == 0.1) %>%
select(-confidence_threshold)
BirdNET_PR_results_by_recording_and_habitat_conf35 <- BirdNET_PR_results_by_recording_and_habitat %>%
filter(confidence_threshold == 0.35) %>%
select(-confidence_threshold)
# Checking the normality of the distribution of the recall and precision variables to determine whether we can perform an ANOVA analysis or not
shapiro.test(BirdNET_PR_results_by_recording_and_habitat_conf10$rec_recall)
hist(BirdNET_PR_results_by_recording_and_habitat_conf10$rec_recall)
shapiro.test(BirdNET_PR_results_by_recording_and_habitat_conf10$rec_precision)
hist(BirdNET_PR_results_by_recording_and_habitat_conf10$rec_precision)
# The distribution of recall and precision values is not normal. Therefore, we have to transform them before we can perform the ANOVA analysis.
# Nonetheless, neither sqrt nor logarithmic transformations transform the recall and precision distributions into normal ones.
# Thus, a Kruskal-Wallis test will have to be performed insted of an ANOVA.
kruskal.test(rec_recall ~ habitat, data = BirdNET_PR_results_by_recording_and_habitat_conf10)
kruskal.test(rec_precision ~ habitat, data = BirdNET_PR_results_by_recording_and_habitat_conf10)
BirdNET_PR_results_by_recording_and_habitat_conf10 <- BirdNET_PR_results_by_recording_and_habitat_conf10 %>%
mutate(rec_F1_score = 2 * 1 * rec_precision * rec_recall / (rec_precision + rec_recall))
BirdNET_PR_results_by_recording_and_habitat_conf10[is.na(BirdNET_PR_results_by_recording_and_habitat_conf10)] = 0
kruskal.test(rec_F1_score ~ habitat, data = BirdNET_PR_results_by_recording_and_habitat_conf10)
# Habitat does not seem to have a significant impact on neither recall nor precision.
BirdNET_recall_results_by_recording_conf10 <- melt(setDT(BirdNET_PR_results_by_recording_and_habitat_conf10 %>%
select(recording_id, rec_recall)), id.vars = "recording_id", variable.name = "metric", value.name = "value")
BirdNET_precision_results_by_recording_conf10 <- melt(setDT(BirdNET_PR_results_by_recording_and_habitat_conf10 %>%
select(recording_id, rec_precision)), id.vars = "recording_id", variable.name = "metric", value.name = "value")
BirdNET_recall_results_by_recording_conf35 <- melt(setDT(BirdNET_PR_results_by_recording_and_habitat_conf35 %>%
select(recording_id, rec_recall)), id.vars = "recording_id", variable.name = "metric", value.name = "value")
BirdNET_precision_results_by_recording_conf35 <- melt(setDT(BirdNET_PR_results_by_recording_and_habitat_conf35 %>%
select(recording_id, rec_precision)), id.vars = "recording_id", variable.name = "metric", value.name = "value")
BirdNET_recall_and_precision_results_by_habitat_conf35 <- union_all(BirdNET_recall_results_by_recording_conf35, BirdNET_precision_results_by_recording_conf35) %>%
left_join(BirdNET_PR_results_by_recording_and_habitat_conf35 %>%
select(recording_id, habitat),
by = "recording_id")
jpeg(file = paste0(R_plots_path, "/", algorithm, " precision and recall analysis/precision_and_recall_by_habitat.jpeg"), width = 3000, height = 2400, res = 500)
ggplot(BirdNET_recall_and_precision_results_by_habitat_conf35, aes(x = habitat, y = value, fill = metric)) +
geom_boxplot() +
xlab("Habitat") +
ylab("Value") +
labs(fill = "Metric") +
ggtitle("rec_precision and rec_recall distributions by dominant habitat") +
theme_bw() +
scale_fill_manual(values = c("#E4959C", "#95B5DA"))
dev.off()
# Checking the normality of the NDSI index distribution to determine whether we can perform a Pearson correlation analysis or not
shapiro.test(BirdNET_PR_results_by_recording_and_habitat_conf10$NDSI_left)
hist(BirdNET_PR_results_by_recording_and_habitat_conf10$NDSI_left)
# The distribution of NDSI, recall and precision values is not normal.
# Therefore, we have to transform them before we can perform the Pearson's correlation analysis.
# Nonetheless, neither sqrt nor logarithmic transformations transform the NDSI, recall or precision distributions into normal ones.
# Thus, a Spearman's correlation test will have to be performed insted of a Pearson's one.
# The NDSI index has a significant influence on the precision of the algorithm (r = 0.128, p-value = 0.053)
cor.test(BirdNET_PR_results_by_recording_and_habitat_conf10$NDSI_left, BirdNET_PR_results_by_recording_and_habitat_conf10$rec_precision, method = "spearman")
# The NDSI index has a significant influence on the recall of the algorithm (r = 0.283, p-value = 1.463e-5)
cor.test(BirdNET_PR_results_by_recording_and_habitat_conf10$NDSI_left, BirdNET_PR_results_by_recording_and_habitat_conf10$rec_recall, method = "spearman")
BirdNET_F1_results_by_recording_and_habitat_conf10 <- BirdNET_PR_results_by_recording_and_habitat_conf10 %>%
mutate(rec_F1_score = 2 * 1 * rec_precision * rec_recall / (rec_precision + rec_recall))
BirdNET_F1_results_by_recording_and_habitat_conf10[is.na(BirdNET_F1_results_by_recording_and_habitat_conf10)] = 0
# The NDSI index has a significant influence on the F1-score of the algorithm (r = 0.144, p-value = 0.03)
cor.test(BirdNET_F1_results_by_recording_and_habitat_conf10$NDSI_left, BirdNET_F1_results_by_recording_and_habitat_conf10$rec_F1, method = "spearman")
jpeg(file = paste0(R_plots_path, "/", algorithm, " precision analysis/precision_by_anthropic_noise.jpeg"), width = 3200, height = 2500, res = 500)
ggplot(BirdNET_PR_results_by_recording_and_habitat_conf10, aes(x=NDSI_left, y=rec_precision)) +
geom_point(color = "black") +
geom_smooth(method = lm, se = TRUE) +
xlab("NDSI score") +
ylab("rec_precision") +
ggtitle(paste0(algorithm, " precision by NDSI score")) +
theme(panel.background = element_blank(),
axis.line = element_line())
dev.off()
jpeg(file = paste0(R_plots_path, "/", algorithm, " recall analysis/recall_by_anthropic_noise.jpeg"), width = 3200, height = 2500, res = 500)
ggplot(BirdNET_PR_results_by_recording_and_habitat_conf10, aes(x=NDSI_left, y=rec_recall)) +
geom_point(color = "black") +
geom_smooth(method = lm, se = TRUE) +
xlab("NDSI score") +
ylab("rec_recall") +
ggtitle(paste0(algorithm, " recall by NDSI score")) +
theme(panel.background = element_blank(),
axis.line = element_line())
dev.off()
jpeg(file = paste0(R_plots_path, "/", algorithm, " precision and recall analysis/F1-score_by_anthropic_noise.jpeg"), width = 3200, height = 2500, res = 500)
ggplot(BirdNET_F1_results_by_recording_and_habitat_conf10, aes(x=NDSI_left, y=rec_F1_score)) +
geom_point(color = "black") +
geom_smooth(method = lm, se = TRUE) +
xlab("NDSI score") +
ylab("rec_F1-score") +
ggtitle(paste0(algorithm, " F1-score by NDSI score")) +
theme(panel.background = element_blank(),
axis.line = element_line())
dev.off()
# ------------------------Recall by sample size analysis------------------------
global_detection_results <- read.csv(paste0(CSV_path, "/global_detection_results_by_recording_subset.csv"))
grouped_global_detection_results <- global_detection_results %>%
group_by(n_recordings_sampled, minimum_confidence_threshold) %>%
summarize(ds_TPR = mean(TPR),
ds_FPR = mean(FPR),
ds_F1 = mean(F1),
ds_TPR_to_FPR_ratio = ds_TPR/ds_FPR,
ds_TPR_minus_FPR = mean(TPR-FPR),
proportion_of_correct_species = mean(n_species_correctly_detected / (n_species_correctly_detected + n_species_incorrectly_detected)))
jpeg(file = paste0(R_plots_path, "/", algorithm, " recall analysis/ds_TPR_by_n_recordings_sampled.jpeg"), width = 4000, height = 2500, res = 500)
ggplot(grouped_global_detection_results, aes(x = as.numeric(n_recordings_sampled), y = ds_TPR, fill = as.factor(minimum_confidence_threshold))) +
geom_bar(position = position_nudge(x = 0.5), stat = "identity",
colour = 'black') +
xlab("Number of recordings sampled") +
ylab("ds_TPR") +
ylim(0, 0.75) +
labs(fill = "Minimum confidence\nthreshold used") +
scale_fill_manual(values = c("#2b4056", "#3874a5", "#56b1f7")) +
ggtitle("True Positive Rate at the dataset level by number of recordings sampled") +
theme_bw()
dev.off()
jpeg(file = paste0(R_plots_path, "/", algorithm, " recall analysis/ds_FPR_by_n_recordings_sampled.jpeg"), width = 4000, height = 2500, res = 500)
ggplot(grouped_global_detection_results, aes(x = as.numeric(n_recordings_sampled), y = ds_FPR, fill = as.factor(minimum_confidence_threshold))) +
geom_bar(position = position_nudge(x = 0.5), stat = "identity",
colour = 'black') +
xlab("Number of recordings sampled") +
ylab("ds_FPR") +
ylim(0, 0.75) +
labs(fill = "Minimum confidence\nthreshold used") +
scale_fill_manual(values = c("#2b4056", "#3874a5", "#56b1f7")) +
ggtitle("False Positive Rate at the dataset level by number of recordings sampled") +
theme_bw()
dev.off()
jpeg(file = paste0(R_plots_path, "/", algorithm, " precision and recall analysis/ds_F1-score_by_n_recordings_sampled_stacked_bar_plot.jpeg"), width = 4000, height = 2500, res = 500)
ggplot(grouped_global_detection_results, aes(x = as.numeric(n_recordings_sampled), y = ds_F1, fill = as.factor(minimum_confidence_threshold))) +
geom_bar(position = position_nudge(x = 0.5), stat = "identity",
colour = 'black') +
xlab("Number of recordings sampled") +
ylab("ds_F1-score") +
ylim(0, 0.75) +
labs(fill = "Minimum confidence\nthreshold used") +
scale_fill_manual(values = c("#2b4056", "#3874a5", "#56b1f7")) +
ggtitle("F1-score at the dataset level by number of recordings sampled") +
theme_bw()
dev.off()
jpeg(file = paste0(R_plots_path, "/", algorithm, " precision and recall analysis/ds_F1-score_by_n_recordings_sampled_unstacked_bar_plot.jpeg"), width = 5000, height = 3200, res = 500)
ggplot(grouped_global_detection_results, aes(x = as.numeric(n_recordings_sampled), y = ds_F1, fill = as.factor(minimum_confidence_threshold))) +
geom_bar(position = "dodge", stat = "identity",
colour = 'black') +
xlab("Number of recordings sampled") +
ylab("ds_F1-score") +
ylim(0, 0.75) +
labs(fill = "Minimum confidence\nthreshold used") +
scale_fill_manual(values = c("#2b4056", "#3874a5", "#56b1f7")) +
ggtitle("F1-score at the dataset level by number of recordings sampled") +
theme_bw()
dev.off()
jpeg(file = paste0(R_plots_path, "/", algorithm, " recall analysis/ds_TPR_to_FPR_ratio_by_n_recordings_sampled.jpeg"), width = 4000, height = 2500, res = 500)
ggplot(grouped_global_detection_results %>%
arrange(desc(minimum_confidence_threshold)), aes(x = as.numeric(n_recordings_sampled), y = ds_TPR_to_FPR_ratio, fill = as.factor(minimum_confidence_threshold))) +
geom_bar(position = position_nudge(x = 0.5),
stat = "identity",
colour = 'black') +
xlab("Number of recordings sampled") +
ylab("ds_TPR to ds_FPR ratio") +
labs(fill = "Minimum confidence\nthreshold used") +
scale_fill_manual(values = c("#2b4056", "#3874a5", "#56b1f7")) +
ggtitle("Ratio between TPR and FPR at the dataset level by number of recordings sampled") +
theme_bw()
dev.off()
jpeg(file = paste0(R_plots_path, "/", algorithm, " recall analysis/ds_TPR_minus_FPR_by_n_recordings_sampled.jpeg"), width = 4000, height = 2500, res = 500)
ggplot(grouped_global_detection_results, aes(x = as.numeric(n_recordings_sampled), y = ds_TPR_minus_FPR)) +
geom_point(position = position_nudge(x = 0.5),
stat = "identity",
color = 'black',
shape=21,
size=2,
aes(fill = as.factor(minimum_confidence_threshold))) +
xlab("Number of recordings sampled") +
ylab("ds_TPR - ds_FPR") +
labs(fill = "Minimum confidence\nthreshold used") +
scale_fill_manual(values = c("#2b4056", "#3874a5", "#56b1f7")) +
ggtitle("TPR minus FPR at the dataset level by number of recordings sampled") +
theme_bw()
dev.off()
jpeg(file = paste0(R_plots_path, "/", algorithm, " recall analysis/proportion_of_correct_species_by_n_recordings_sampled.jpeg"), width = 4000, height = 2500, res = 500)
ggplot(grouped_global_detection_results, aes(x = as.numeric(n_recordings_sampled), y = proportion_of_correct_species)) +
geom_point(position = position_nudge(x = 0.5),
stat = "identity",
color = 'black',
shape=21,
size=2,
aes(fill = as.factor(minimum_confidence_threshold))) +
xlab("Number of recordings sampled") +
ylab("Proportion of species detected \nthat are actually present") +
labs(fill = "Minimum confidence\nthreshold used") +
scale_fill_manual(values = c("#2b4056", "#3874a5", "#56b1f7")) +
ggtitle("Proportion of species detected by BirdNET that are actually present \nin the acoustic dataset, by number of recordings sampled") +
theme_bw()
dev.off()
ds_TPR_lm <- lm(TPR ~ log(n_recordings_sampled) + as.numeric(minimum_confidence_threshold), data = global_detection_results)
summary(ds_TPR_lm)
# It appears that there is a linear correlation between the TPR at the dataset level and the logarithm of the number of recordings sampled
# after controlling for the minimum confidence threshold used (p < 2e-16)
ds_FPR_lm <- lm(FPR ~ log(n_recordings_sampled) + as.numeric(minimum_confidence_threshold), data = global_detection_results)
summary(ds_FPR_lm)
# The same does seem to be true as well of the FPR at the dataset level (p < 2e-16)
ds_F1_lm <- lm(F1 ~ log(n_recordings_sampled) + as.numeric(minimum_confidence_threshold), data = global_detection_results)
summary(ds_F1_lm)
# It appears that there is a linear correlation between the F1-score at the dataset level and the logarithm of the number of recordings sampled
# after controlling for the minimum confidence threshold used (p < 2e-16)
# Precision and recall results by recorder type
BirdNET_PR_results_by_recorder <- BirdNET_PR_results_by_recording_and_habitat_conf10 %>%
left_join(recording_info_extended %>%
select(recording_id, ARU),
by = "recording_id") %>%
mutate(f1_score = 2 * rec_precision * rec_recall / (rec_precision + rec_recall))
BirdNET_PR_results_by_recorder[is.na(BirdNET_PR_results_by_recorder)] <- 0
aov_by_recorder_habitat_and_noise <- aov(f1_score ~ ARU + NDSI_left + habitat, BirdNET_PR_results_by_recorder)
summary(aov_by_recorder_habitat_and_noise)
jpeg(file = paste0(R_plots_path, "/", algorithm, " precision and recall analysis/F1_scores_by_recorder.jpeg"), width = 3000, height = 2400, res = 500)
ggplot(BirdNET_PR_results_by_recorder, aes(x = ARU, y = f1_score)) +
geom_boxplot(fill = "#84B8E1") +
xlab("Recorder") +
ylab("rec_F1-score") +
ggtitle("F1-scores at the recording level by recorder used") +
theme_bw()
dev.off()
BirdNET_recall_and_precision_results_by_recorder <- union_all(BirdNET_recall_results_by_recording_conf35, BirdNET_precision_results_by_recording_conf35) %>%
left_join(BirdNET_PR_results_by_recorder %>%
select(recording_id, ARU),
by = "recording_id") %>%
rename("recorder" = "ARU")
jpeg(file = paste0(R_plots_path, "/", algorithm, " precision and recall analysis/precision_and_recall_by_recorder.jpeg"), width = 3000, height = 2400, res = 500)
ggplot(BirdNET_recall_and_precision_results_by_recorder, aes(x = recorder, y = value, fill = metric)) +
geom_boxplot() +
xlab("Recorder") +
ylab("Value") +
labs(fill = "Metric") +
ggtitle("rec_precision and rec_recall distributions by recorder used") +
theme_bw() +
scale_fill_manual(values = c("#E4959C", "#95B5DA"))
dev.off()
n_recordings_by_habitat_and_recorder <- BirdNET_PR_results_by_recorder %>%
group_by(habitat, ARU) %>%
summarize(n_recordings = n()) %>%
arrange(ARU, habitat)
# Checking the normality of the distribution of the precision and recall to determine whether we can perform an ANOVA analysis or not
# if (length(BirdNET_PR_results_by_recorder$rec_precision) < 5000) {
#   shapiro.test(BirdNET_PR_results_by_recorder$rec_precision)
#   hist(BirdNET_PR_results_by_recorder$rec_precision)
#
#   shapiro.test(BirdNET_PR_results_by_recorder$rec_recall)
#   hist(BirdNET_PR_results_by_recorder$rec_recall)
# }
# The distributions of precision and recall levels are not normal. Therefore, we have to transform the data before we can perform the ANOVA analysis.
# Nonetheless, neither sqrt nor logarithmic transformations transform the distribution into a normal one.
# Thus, a Kruskal-Wallis test will have to be performed insted of an ANOVA.
# Since it isn't possible to control for confounding factors in the Kruskal-Wallis test,
# we remove data from alpine meadow recordings due to their higher levels of geophonic noise
kruskal.test(rec_precision ~ ARU, data = BirdNET_PR_results_by_recorder %>%
filter(habitat != "alpine meadow"))
kruskal.test(rec_recall ~ ARU, data = BirdNET_PR_results_by_recorder %>%
filter(habitat != "alpine meadow"))
kruskal.test(f1_score ~ ARU, data = BirdNET_PR_results_by_recorder %>%
filter(habitat != "alpine meadow"))
kruskal.test(rec_precision ~ habitat, data = BirdNET_PR_results_by_recorder %>%
filter(habitat != "alpine meadow"))
kruskal.test(rec_recall ~ habitat, data = BirdNET_PR_results_by_recorder %>%
filter(habitat != "alpine meadow"))
kruskal.test(f1_score ~ habitat, data = BirdNET_PR_results_by_recorder %>%
filter(habitat != "alpine meadow"))
# The recorder type does not seem to have a significant impact on recall but not on precision.
# This effect would probably go away when controlling for habitat, but this would require using a Friedman's test.
# It's not possible to use a Friedman's test because our dataset is incomplete (e.g. there are no data for SMMicros in alpine meadows), so we cannot control for habitat.
jpeg(file = paste0(R_plots_path, "/", algorithm, " precision and recall analysis/f1_score_by_recorder_and_habitat.jpeg"), width = 3000, height = 2400, res = 500)
ggplot(BirdNET_PR_results_by_recorder %>%
rename("Recorder" = "ARU"), aes(x = habitat, y = f1_score)) +
geom_boxplot(outlier.shape = NA) +
xlab("Habitat") +
ylab("rec_F1-score") +
geom_point(aes(color = Recorder), position=position_jitterdodge(dodge.width = 0.6, jitter.width = 0.25), alpha=0.95, size = 1.5) +
ggtitle("F1-scores at the recording level by habitat and recorder used") +
scale_color_manual(values = wes_palette("GrandBudapest2", n = 4)) +
# scale_color_manual(values = c("#E4959C", "#95B5DA", "#795c00", "#96be25")) +
theme_bw()
dev.off()
# Plotting PR and ROC curves based on results at the dataset level
global_detection_results_by_all_thresholds <- read.csv(paste0(CSV_path, "/global_detection_results_by_all_thresholds.csv")) %>%
mutate(minimum_confidence_threshold = as.numeric(minimum_confidence_threshold))
global_detection_results_by_all_thresholds[is.na(global_detection_results_by_all_thresholds)] <- 0
ds_roc_auc <- -trapz(global_detection_results_by_all_thresholds$TPR, global_detection_results_by_all_thresholds$FPR)/max(global_detection_results_by_all_thresholds$FPR)
ds_pr_auc <- trapz(global_detection_results_by_all_thresholds$precision, global_detection_results_by_all_thresholds$TPR)/max(global_detection_results_by_all_thresholds$TPR)
overlap_label_regex <- qdapRegex::ex_between(overlap_label, "(", ")")[[1]]
ds_ROC_title <- paste0(case_when(algorithm == "Google" ~ "Google",
TRUE ~ overlap_label_regex), filtered_label, " - ds_ROC curve, AUC = ", round(ds_roc_auc, digits = 3))
ds_PR_title <- paste0(case_when(algorithm == "Google" ~ "Google",
TRUE ~ overlap_label_regex), filtered_label, " - ds_PR curve, AUC = ", round(ds_pr_auc, digits = 3))
# ROC curve
jpeg(file = paste0("../R plots", algorithm_text, BirdNET_version, ds_text, filtered_text, overlap_text, paste0("/", algorithm, " precision and recall analysis/ds_ROC_curve.jpeg")), width = 3300, height = 2400, res = 500)
ggplot(global_detection_results_by_all_thresholds, aes(x = FPR, y = TPR, color = minimum_confidence_threshold)) +
geom_point() +
guides(color = guide_colorbar(reverse = FALSE, barheight = 10)) +
xlab("ds_FPR") +
ylab("ds_TPR") +
ylim(c(0, 1)) +
xlim(c(0, 1)) +
labs(color = "Confidence \n  threshold") +
ggtitle(ds_ROC_title) +
theme_bw() +
# Eliminates background, gridlines, and chart border
theme(
plot.background = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.border = element_blank(),
plot.title = element_text(hjust = 0.5,
margin = margin(0,0,10,0))
) +
# Draws x and y axis line
theme(axis.line = element_line(color = 'black'))
dev.off()
# Precision-Recall curve
jpeg(file = paste0("../R plots", algorithm_text, BirdNET_version, ds_text, filtered_text, overlap_text, paste0("/", algorithm, " precision and recall analysis/ds_PR_curve.jpeg")), width = 3300, height = 2400, res = 500)
ggplot(global_detection_results_by_all_thresholds, aes(x = TPR, y = precision, color = minimum_confidence_threshold)) +
geom_point() +
guides(color = guide_colorbar(reverse = FALSE, barheight = 10)) +
xlab("ds_recall") +
ylab("ds_precision") +
ylim(c(0.35, 1)) +
xlim(c(0, 1)) +
labs(color = "Confidence \n  threshold") +
ggtitle(ds_PR_title) +
theme_bw() +
# Eliminates background, gridlines, and chart border
theme(
plot.background = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.border = element_blank(),
plot.title = element_text(hjust = 0.5,
margin = margin(0,0,10,0))
) +
# Draws x and y axis line
theme(axis.line = element_line(color = 'black'))
dev.off()
source("~/Escriptori/Màster Ecologia/TFM/R scripts/PR_results_analysis.R", echo=TRUE)
source("~/Escriptori/Màster Ecologia/TFM/R scripts/randomize_results_by_recording_subset.R", echo=TRUE)
